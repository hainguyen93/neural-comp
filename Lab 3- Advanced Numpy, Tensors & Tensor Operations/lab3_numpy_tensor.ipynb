{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab3_numpy_tensor.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "pycharm-58ebb752",
      "language": "python",
      "display_name": "PyCharm (TA_2019)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a6okRUxVEUTI"
      },
      "source": [
        "# Neural Computation (Autumn 2019)\n",
        "# Lab 3: Advanced Numpy, Tensors & Tensor Operations\n",
        " In this tutorial, we cover:\n",
        "- Advanced Numpy like broadcasting and sorting\n",
        "- Tensors (a fundamental data structure used in Neural Computation)\n",
        "- Tensor Operations.\n",
        "\n",
        "# Section 1: Advanced Numpy\n",
        "\n",
        "As always, we need to import the numpy library via  `import` command:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kL_RnkzQGQUk",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "D4qsNXQpEUYT"
      },
      "source": [
        "## Broadcasting\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X12mGP2NEUYT"
      },
      "source": [
        "Broadcasting is a powerful mechanism that allows numpy to work with arrays of different shapes when performing arithmetic operations. Frequently we have a smaller array and a larger array, and we want to use the smaller array multiple times to perform some operation on the larger array.\n",
        "\n",
        "For example, suppose that we want to add a constant vector to each row of a matrix. We could do it like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ie5KgfeZEUYT",
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {}
      },
      "source": [
        "# We will add the vector v to each row of the matrix x,\n",
        "# storing the result in the matrix y\n",
        "x = np.array([[1,2,3], [4,5,6], [7,8,9], [10, 11, 12]])\n",
        "v = np.array([1, 0, 1])\n",
        "y = np.empty_like(x)   # Create an empty matrix with the same shape as x\n",
        "\n",
        "# Add the vector v to each row of the matrix x with an explicit loop\n",
        "for i in range(4):\n",
        "    y[i, :] = x[i, :] + v\n",
        "\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yRUEtOb3EUYU"
      },
      "source": [
        "This works; however when the matrix `x` is very large, computing an explicit loop in Python could be slow. Note that adding the vector v to each row of the matrix `x` is equivalent to forming a matrix `vv` by stacking multiple copies of `v` vertically, then performing elementwise summation of `x` and `vv`. We could implement this approach like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zyEc0FpFEUYU",
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "is_executing": false
        },
        "colab": {}
      },
      "source": [
        "vv = np.tile(v, (4, 1))  # Stack 4 copies of v on top of each other\n",
        "print(vv)                 # Prints \"[[1 0 1]\n",
        "                         #          [1 0 1]\n",
        "                         #          [1 0 1]\n",
        "                         #          [1 0 1]]\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lEw1IvIfEUYW",
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {}
      },
      "source": [
        "y = x + vv  # Add x and vv elementwise\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MLg-9bEhEUYW"
      },
      "source": [
        "Numpy broadcasting allows us to perform this computation without actually creating multiple copies of v. Consider this version, using broadcasting:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fTtigXZ5EUYX",
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# We will add the vector v to each row of the matrix x,\n",
        "# storing the result in the matrix y\n",
        "x = np.array([[1,2,3], [4,5,6], [7,8,9], [10, 11, 12]])\n",
        "v = np.array([1, 0, 1])\n",
        "y = x + v  # Add v to each row of x using broadcasting\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ESJW-5UQEUYX"
      },
      "source": [
        "The line `y = x + v` works even though `x` has shape `(4, 3)` and `v` has shape `(3,)` due to broadcasting; this line works as if v actually had shape `(4, 3)`, where each row was a copy of `v`, and the sum was performed elementwise.\n",
        "\n",
        "Broadcasting two arrays together follows these rules:\n",
        "\n",
        "1. If the arrays do not have the same rank, prepend the shape of the lower rank array with 1s until both shapes have the same length.\n",
        "2. The two arrays are said to be compatible in a dimension if they have the same size in the dimension, or if one of the arrays has size 1 in that dimension.\n",
        "3. The arrays can be broadcast together if they are compatible in all dimensions.\n",
        "4. After broadcasting, each array behaves as if it had shape equal to the elementwise maximum of shapes of the two input arrays.\n",
        "5. In any dimension where one array had size 1 and the other array had size greater than 1, the first array behaves as if it were copied along that dimension\n",
        "\n",
        "If this explanation does not make sense, try reading the explanation from the [documentation](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html) or this [explanation](http://wiki.scipy.org/EricsBroadcastingDoc).\n",
        "\n",
        "Functions that support broadcasting are known as universal functions. You can find the list of all universal functions in the [documentation](http://docs.scipy.org/doc/numpy/reference/ufuncs.html#available-ufuncs).\n",
        "\n",
        "Here are some applications of broadcasting:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fi9l6GnsEUYX",
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {}
      },
      "source": [
        "# Compute outer product of vectors\n",
        "v = np.array([1,2,3])  # v has shape (3,)\n",
        "w = np.array([4,5])    # w has shape (2,)\n",
        "# To compute an outer product, we first reshape v to be a column\n",
        "# vector of shape (3, 1); we can then broadcast it against w to yield\n",
        "# an output of shape (3, 2), which is the outer product of v and w:\n",
        "\n",
        "print(np.reshape(v, (3, 1)) * w)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MyLfp3mzEUYZ",
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {}
      },
      "source": [
        "# Add a vector to each row of a matrix\n",
        "x = np.array([[1,2,3], [4,5,6]])\n",
        "# x has shape (2, 3) and v has shape (3,) so they broadcast to (2, 3),\n",
        "# giving the following matrix:\n",
        "\n",
        "print(x + v)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Io0kqfwAEUYZ",
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {}
      },
      "source": [
        "# Add a vector to each column of a matrix\n",
        "# x has shape (2, 3) and w has shape (2,).\n",
        "# If we transpose x then it has shape (3, 2) and can be broadcast\n",
        "# against w to yield a result of shape (3, 2); transposing this result\n",
        "# yields the final result of shape (2, 3) which is the matrix x with\n",
        "# the vector w added to each column. Gives the following matrix:\n",
        "\n",
        "print((x.T + w).T)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uqdy2OQqEUYa",
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {}
      },
      "source": [
        "# Another solution is to reshape w to be a row vector of shape (2, 1);\n",
        "# we can then broadcast it directly against x to produce the same\n",
        "# output.\n",
        "print(x + np.reshape(w, (2, 1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wh3-5KSHEUYb",
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {}
      },
      "source": [
        "# Multiply a matrix by a constant:\n",
        "# x has shape (2, 3). Numpy treats scalars as arrays of shape ();\n",
        "# these can be broadcast together to shape (2, 3), producing the\n",
        "# following array:\n",
        "print(x * 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jFmroQo3EUYc"
      },
      "source": [
        "Broadcasting typically makes your code more concise and faster, so you should strive to use it where possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7W9PFWAiEUYc"
      },
      "source": [
        "This brief overview has touched on many of the important things that you need to know about numpy, but is far from complete. Check out the [numpy reference](http://docs.scipy.org/doc/numpy/reference/) to find out much more about numpy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HW0ccFB6vXl0",
        "colab_type": "text"
      },
      "source": [
        "## Data Types for ndarrays\n",
        "\n",
        "The *data type* or `dtype` is a special object containing the information (or *metadata*, data about data) the ndarray needs to interpret a chunk of memory as a particular type of data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ouo7s1MvppW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arr1 = np.array([1, 2, 3], dtype = np.float64)\n",
        "\n",
        "print(arr1)\n",
        "print(arr1.dtype)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxacg02OwEcS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arr2 = np.array([1, 2, 3], dtype = np.int32)\n",
        "\n",
        "print(arr2)\n",
        "print(arr2.dtype)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HbmHvmowKx7",
        "colab_type": "text"
      },
      "source": [
        "Note the difference between the types of the values in each two arrays, `arr1` and `arr2`. \n",
        "\n",
        "The numerical dtypes are named the same way: a type name, like `float` or `int`, followed by a number indicating the number of bits per element. A standard double-precision floating-point value (what’s used under the hood in Python’s `float` object) takes up 8 bytes or 64 bits. Thus, this type is known in NumPy as `float64`. Some examples of Numpy data types as follows:\n",
        "\n",
        "    int8, uint8 : signed and unsigned 8-bit (1 byte) integer types\n",
        "    int16, uint16 :  signed and unsigned 16-bit integer types\n",
        "    int32, uint32 : signed and unsigned 32-bit integer types\n",
        "    int64, uint64 : signed and unsiged 64-bit integer types\n",
        "\n",
        "    float16 : Half-precision floating point\n",
        "    float32 : Standard single-precision floating point\n",
        "    float64 : Standard double-precision floating point"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XQnLWr69FmHb"
      },
      "source": [
        "## Setting Array Values by Broadcasting\n",
        "The same broadcasting rule governing arithmetic operations also applies to setting values via array indexing. In a simple case, we can do things like:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PWtmnjVaF7l6",
        "colab": {}
      },
      "source": [
        "arr = np.zeros((4,3))\n",
        "print(arr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAXmQg5HxkJq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arr[:] = 5\n",
        "print(arr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JlPcb9U4HNo2"
      },
      "source": [
        "However, if we had a one-dimensional array of values we wanted to set into the columns of the array, we can do that as long as the shape is compatible:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IX7mcMCvHQF5",
        "colab": {}
      },
      "source": [
        "arr[:2] = [[-1.37], [0.509]]\n",
        "arr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3nobgnDhHl4r"
      },
      "source": [
        "## Sorting\n",
        "Like Python’s built-in list, the ndarray `sort` instance method is an in-place sort, meaning that the array contents are rearranged without producing a new array:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RcshSSCiJYE5",
        "colab": {}
      },
      "source": [
        "arr = np.random.randn(6)\n",
        "print(arr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "omQOTuBRK3MD",
        "colab": {}
      },
      "source": [
        "arr.sort()  # in-place sorting in ascending order\n",
        "print(arr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zNuWzcyOJo27"
      },
      "source": [
        "When sorting arrays in-place, remember that if the array is a view on a different ndarray, the original array will be modified:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UB2znzm4Jug8",
        "colab": {}
      },
      "source": [
        "arr = np.random.randn(3, 5)\n",
        "print('Before sorting: \\n', arr)\n",
        "\n",
        "arr[:, 0].sort()  # sort first column values in-place\n",
        "print('After sorting: \\n', arr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MKw-FOTJKQEK"
      },
      "source": [
        "On the other hand, `numpy.sort` creates a new, sorted copy of an array. Otherwise, it accepts the same arguments (such as kind ) as `ndarray.sort` :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zL2XykwtKYPC",
        "colab": {}
      },
      "source": [
        "arr = np.random.randn(5)\n",
        "arr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EK-8KafDKL-q",
        "colab": {}
      },
      "source": [
        "np.sort(arr)  # create a new array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qw--M5lKKIrh",
        "colab": {}
      },
      "source": [
        "arr  # the original array does not change"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TH43trdCK9UV"
      },
      "source": [
        "All of these sort methods take an axis argument for sorting the sections of data along the passed axis independently:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kVFabYOnMUkt",
        "colab": {}
      },
      "source": [
        "arr = np.random.randn(3, 5)\n",
        "print('Before sorting \\n', arr)\n",
        "\n",
        "arr.sort(axis=0)  # sort columns in ascending order\n",
        "print('After sorting \\n', arr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cqonc-ChK_RT",
        "colab": {}
      },
      "source": [
        "arr = np.random.randn(3, 5)\n",
        "print('Before sorting \\n', arr)\n",
        "\n",
        "arr.sort(axis=1)  # sort rows in ascending order\n",
        "print('After sorting \\n', arr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "W0k1S_g1MGsr"
      },
      "source": [
        "You may notice that none of the sort methods have an option to sort in descending order. This is a problem in practice because array slicing produces views, thus not producing a copy or requiring any computational work. The following exercise will ask you to propose a solution to this problem.\n",
        "\n",
        "### Exercise: \n",
        "\n",
        "Given a 2-dimensional array as follows:\n",
        "  \n",
        "    [[5, 4, 9],\n",
        "     [8, 1, 5],\n",
        "     [3, 0, 3]]\n",
        "  \n",
        "Could you sort the array to obtain the following array?\n",
        "\n",
        "    [[9, 5, 4], \n",
        "     [8, 5, 1], \n",
        "     [3, 3, 0]]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-sRY8z15MN0Z",
        "colab": {}
      },
      "source": [
        "# write your solution here\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPx9RPwtus2z",
        "colab_type": "text"
      },
      "source": [
        "Similarly, write codes to produce the following array:\n",
        "\n",
        "    [[8, 4, 9],\n",
        "     [5, 1, 5],\n",
        "     [3, 0, 3]]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvufBBGEutjy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# write your solution here\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "A5efqxFJVNBm"
      },
      "source": [
        "# Section 2: Data Representations for Neural Networks\n",
        "In the previous section, we started from data stored in multidimentional Numpy array, also called **tensors**. In general, all current machine-learning system use tensors as their basic data structure. Tensors are fundamental to the field -- so fundamental that Google's TensorFlow was named after them. So what's a tensor?\n",
        "\n",
        "At its core, a tensor is a container for data -- almost always numerical data. So, it's a container for numbers. You may be already familiar with matrices, which are 2D tensors: tensors are a geeralisation of matrices to an arbitrary number of dimensions (note that in the context of tensors, a dimension is called an *axis*).\n",
        "\n",
        "## Scalar (0D tensors)\n",
        "\n",
        "A tensor that contains only one number is called a scalar (or scalar tensor, or 0-dimensional tensor, or 0D tensor). In Numpy, a `float32` or `float64` number is a scalar tensor. You may display the number of axes of a Numpy tensor via the `ndim` attribute; a scalar tensor has 0 axes (`ndim==0`). The number of axes of a tensor is also called its *ranks*. Here's a Numpy scalar:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r7vcLfIjXYyO",
        "colab": {}
      },
      "source": [
        "x = np.array(12)  \n",
        "x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Mzs2_OErXdCy",
        "colab": {}
      },
      "source": [
        "x.ndim  # A scalar has 0 axes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DiYDY57MXifz"
      },
      "source": [
        "## Vectors (1D tensors)\n",
        "An array of number is called a vector, or 1D tensor. A 1D tensor is said to have exactly one axis. Following is a Numpy vector:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5Lb1SiagXfAJ",
        "colab": {}
      },
      "source": [
        "x = np.array([12, 3, 6, 14])\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vNyUibNTX1H6",
        "colab": {}
      },
      "source": [
        "x.ndim  # a vector has exactly one axis"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "75KP7WiUYMIM"
      },
      "source": [
        "This vector has five entries and so is called a 5-dimensional vector. Don’t confuse a 5D vector with a 5D tensor! A 5D vector has only one axis and has five dimensions along its axis, whereas a 5D tensor has five axes (and may have any number of dimensions along each axis). Dimensionality can denote either the number of entries along a specific axis (as in the case of our 5D vector) or the number of axes in a tensor (such as a 5D tensor), which can be confusing at times. In the latter case, it’s technically more correct to talk about a tensor of rank 5 (the rank of a tensor being the number of axes), but the ambiguous notation 5D tensor is common regardless."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TFDKJ2j-YX-s"
      },
      "source": [
        "## Matrices (2D tensors)\n",
        "\n",
        "An array of vectors is a matrix, or 2D tensor. A matrix has two axes (often referred to rows and columns). You may visually interpret a matrix as a rectangular grid of numbers. This is Numpy matrix:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0Q4xDig-YwCr",
        "colab": {}
      },
      "source": [
        "x = np.array([[5, 78, 2, 34, 0],\n",
        "             [6, 79, 3, 35, 1],\n",
        "             [7, 80, 4, 36, 2]])\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DljYwqxsZAfC",
        "colab": {}
      },
      "source": [
        "x.ndim  # a matrix has two axes."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Vzt34WyNZH9t"
      },
      "source": [
        "The entries from the first axis are called the rows, and the entries from the second axis are called the columns. In the previous example, `[5, 78, 2, 34, 0]` is the first row of `x`, and `[5, 6, 7]` is the first column.\n",
        "\n",
        "## 3D tensors and higher-dimensional tensors\n",
        "\n",
        "If you pack such matrices in a new array, you obtain a 3D tensor, which you can visually interpret as a cube of numbers. Following is a Numpy 3D tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qR87P5J6cW5a",
        "colab": {}
      },
      "source": [
        "x = np.array([\n",
        "             [[5, 78, 2, 34, 0],\n",
        "              [6, 79, 3, 35, 1],\n",
        "              [7, 80, 4, 36, 2]],\n",
        "             [[5, 78, 2, 34, 0],\n",
        "              [6, 79, 3, 35, 1],\n",
        "              [7, 80, 4, 36, 2]],\n",
        "             [[5, 78, 2, 34, 0],\n",
        "              [6, 79, 3, 35, 1],\n",
        "              [7, 80, 4, 36, 2]]\n",
        "              ])\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D4DPR_ENdAnG",
        "colab": {}
      },
      "source": [
        "x.ndim  # 3D tensor has three axes "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SyTHsWogdM8t"
      },
      "source": [
        "By packing 3D tensors in an array, you can create a 4D tensor, and so on. In deep learning, you’ll generally manipulate tensors that are 0D to 4D, although you may go up to 5D if you process video data.\n",
        "\n",
        "## Key attributes\n",
        "\n",
        "A tensor is defined by three key attributes:\n",
        "\n",
        "- **Number of axes (rank)**: For instance, a 3D tensor has three axes, and a matrix has two axes. This is also called the tensor's `ndim` in Python libraries such as Numpy.\n",
        "\n",
        "- **Shape**: This is a tuple of integers that describes how many dimensions the tensor has along each axis. For example, the previous matrix has shape of `(3,5)`, and the 3D tensor example has shape `(3,3,5)`. A vector has a shape with a single element, such as `(5,)`, whereas a scalar has an empty shape, `()`.\n",
        "\n",
        "- **Datatype** (usually called `dtype` in Python libraries): This is the type of the data contained in the tensor; for instance, a tensor's type could be `float32`, `uint8`, `float64`, and so on. Note that string tensors do not exist in Numpy (or in most other libraries).\n",
        "\n",
        "\n",
        "## Real-world examples of data tensors\n",
        "\n",
        "Let’s make data tensors more concrete with a few examples similar to what you’ll\n",
        "encounter later. The data you’ll manipulate will almost always fall into one of the following categories (see more real-world examples below):\n",
        "\n",
        "- **Vector data** -- 2D tensor of shape `(samples, features)`, where `samples` denotes the number of samples.\n",
        "\n",
        "- **Timeseries data or sequence data** -- 3D tensors of shape `(samples, timesteps, features)`.\n",
        "\n",
        "- **Images** -- 4D tensor of shape `(samples, channels, height, width)` (in Facebook's Pytorch) or `(samples, height, width, channels)` (in Google's TensorFlow).\n",
        "\n",
        "- **Video** -- 5D tensors of shape `(samples, frames, channels, height, width)`.\n",
        "\n",
        "## Vector data\n",
        "This is the most common case. In such a dataset, each single data point can be encoded as a vector, and thus a batch of data will be encoded as a 2D tensor (that is, an array of vectors), where the first axis is the samples axis and the second axis is the features axis.\n",
        "\n",
        "Let’s take a look at two examples:\n",
        "\n",
        "- An actuarial dataset of people, where we consider each person’s age, ZIP code,\n",
        "and income. Each person can be characterized as a vector of 3 values, and thus\n",
        "an entire dataset of 100,000 people can be stored in a 2D tensor of shape\n",
        "`(100000, 3)`. More specifically, we have in this case `samples` is 100,000 and `features` is a vector of 3 values (age, ZIP and income).\n",
        "\n",
        "- A dataset of text documents, where we represent each document by the counts\n",
        "of how many times each word appears in it (out of a dictionary of 20,000 com-\n",
        "mon words). Each document can be encoded as a vector of 20,000 values (one\n",
        "count per word in the dictionary), and thus an entire dataset of 500 documents\n",
        "can be stored in a tensor of shape `(500, 20000)`.\n",
        "\n",
        "\n",
        "## Timeseries data or sequence data\n",
        "\n",
        "Whenever time matters in your data (or the notion of sequence order), it makes sense to store it in a 3D tensor with an explicit time axis. Each sample can be encoded as a sequence of vectors (a 2D tensor), and thus a batch of data will be encoded as a 3D tensor.\n",
        "\n",
        "The time axis is always the second axis (axis of index 1), by convention. Let’s look at an example:\n",
        " \n",
        " - A dataset of stock prices. Every minute, we store the current price of the stock, the highest price in the past minute, and the lowest price in the past minute. Thus every minute is encoded as a 3D vector, an entire day of trading is\n",
        "encoded as a 2D tensor of shape `(390, 3)` (there are 390 minutes in a trading\n",
        "day), and 250 days’ worth of data can be stored in a 3D tensor of shape `(250,\n",
        "390, 3)`. Here, each sample would be one day's worth of data. Here, we have, in this case, `samples` is 250, `timesteps` is 390 and `features` is 3.\n",
        "\n",
        "## Image data\n",
        "\n",
        "Images typically have three dimensions: height, width, and color depth. Although\n",
        "grayscale images have only a single color channel and could thus be stored in 2D tensors, by convention image tensors are always 3D , with a one-dimensional color channel for grayscale images. \n",
        "\n",
        "For example, a batch of 128 grayscale images (has only one channel) of\n",
        "size 256 × 256 could thus be stored in a tensor of shape `(128, 1, 256, 256)` (in the form of `(samples, channels, height, width)`), and a batch of 128 color images (has three channels for red, green, blue) could be stored in a tensor of shape `(128, 3, 256, 256)`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "59kWzE_yiKrV"
      },
      "source": [
        "# Section 3: Tensor Operations\n",
        "\n",
        "Same as matrices, we can perform element-wise arithmetic between tensors. There are four basic airthmetic operations. We will go through them in the following cells. Usually, we use a captial letter to represent a tensor.\n",
        "\n",
        "First, let's create some tensors as follows:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WJVrIJqOj_l1",
        "colab": {}
      },
      "source": [
        "## from matrix\n",
        "T1 = np.array([[1,2,3], [4,5,6],[7,8,9]])\n",
        "T2 = np.array([[11,12,13], [14,15,16],[17,18,19]])\n",
        "T3 = np.array([[21,22,23], [24,25,26],[27,28,29]])\n",
        "\n",
        "T_m = np.array([T1,T2,T3])\n",
        "\n",
        "print(T_m.shape)\n",
        "print(T_m.ndim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nfIASj0vkYGV",
        "colab": {}
      },
      "source": [
        "T_d = np.array([\n",
        "  [[1,2,3],    [4,5,6],    [7,8,9]],\n",
        "  [[11,12,13], [14,15,16], [17,18,19]],\n",
        "  [[21,22,23], [24,25,26], [27,28,29]],\n",
        "  ])\n",
        "\n",
        "print(T_d.shape)\n",
        "print(T_d.ndim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kO-kZEDpkqzU",
        "colab": {}
      },
      "source": [
        "## check\n",
        "print(T_m-T_d) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mJK_6hpIjeb6"
      },
      "source": [
        "## Tensor addition\n",
        "Given wo tensors with the same dimensions, we can create a new tensor with the same dimensions where each scalar value is the element-wise addition of the scalars in the parent tensors.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rhxN2vChjeb9",
        "colab": {}
      },
      "source": [
        "# define tensor addition\n",
        "def tensor_add(T1, T2):\n",
        "    return T1 + T2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SllE6Jn7jeb_",
        "colab": {}
      },
      "source": [
        "# example of tensor addition\n",
        "print(T1)\n",
        "print(T2)\n",
        "print(tensor_add(T1,T2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cA8by408yJIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "T1 + T2  # element-wise addition"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fB6EO9EEjecA"
      },
      "source": [
        "## Tensor substraction\n",
        "Given wo tensors with the same dimensions, we can create a new tensor with the same dimensions where each scalar value is the element-wise substraction of the scalars in the parent tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Qa9NT_PzjecB",
        "colab": {}
      },
      "source": [
        "def tensor_sub(T1, T2):\n",
        "    return T1-T2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGHoXV8OyUri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tensor_sub(T1, T2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1C15pD4DyRx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "T1 - T2  # element-wise subtraction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Geosvk8DjecD"
      },
      "source": [
        "## Tensor division\n",
        "Given wo tensors with the same dimensions, we can create a new tensor with the same dimensions where each scalar value is the element-wise division of the scalars in the parent tensors. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pNbp18gZjecE",
        "colab": {}
      },
      "source": [
        "#Please note than every element in T2 should not be zero.\n",
        "def tensor_div(T1, T2):\n",
        "    return T1/T2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YzX1jyNymLq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tensor_div(T1, T2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_gliHF5ypbB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "T1 / T2  # element-wise division"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PrnyrndMjecH"
      },
      "source": [
        "## Tensor multiplication\n",
        "There are two types of tensor multiplication, one is called hadamard product and the other one is tensor product."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m5AVrf1sjecH"
      },
      "source": [
        "## Tensor hadamard product (element-wise multiplication)\n",
        "Given wo tensors with the same dimensions, we can create a new tensor with the same dimensions where each scalar value is the element-wise multiplication of the scalars in the parent tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2p7DjYwmjecI",
        "colab": {}
      },
      "source": [
        "def tensor_hprod(T1,T2):\n",
        "    return T1*T2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikNlyfOyy15a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tensor_hprod(T1, T2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYRCdUPay2OT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "T1 * T2  # element-wise multiplication"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SmJbkZo3jecK"
      },
      "source": [
        "## Tensor product\n",
        "\n",
        "We will denote tensor product here as “(x)”. The tensor product is not limited to tensors, but can also be performed on matrices and vectors.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cqeLg0DejecL"
      },
      "source": [
        "### Tensor product for vectors\n",
        "\n",
        "The rules for tensor product for vectors are:\n",
        "\n",
        "$$\n",
        "a =\\begin{pmatrix}\n",
        "a1 & a2\n",
        "\\end{pmatrix} \n",
        "$$\n",
        "\n",
        "\n",
        "$$\n",
        "b =\\begin{pmatrix}\n",
        "b1 & b2\n",
        "\\end{pmatrix} \n",
        "$$\n",
        "\n",
        "Assume c = a(x)b, then\n",
        "\n",
        "$$\n",
        "c =\\begin{pmatrix}\n",
        "a1*b & a2*b\n",
        "\\end{pmatrix} \n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bv8y0zF2jecO"
      },
      "source": [
        "### Tensor product for matrices\n",
        "\n",
        "The rules for tensor product for matrices are:\n",
        "\n",
        "$$\n",
        "a =\\begin{pmatrix}\n",
        "a11 & a12\\\\\n",
        "a21 & a22\n",
        "\\end{pmatrix} \n",
        "$$\n",
        "\n",
        "\n",
        "$$\n",
        "b =\\begin{pmatrix}\n",
        "b11 & b12\\\\\n",
        "b21 & b22\n",
        "\\end{pmatrix} \n",
        "$$\n",
        "\n",
        "Assume c = a(x)b, then\n",
        "\n",
        "$$\n",
        "c =\\begin{pmatrix}\n",
        "a11*b & a12*b\\\\\n",
        "a21*b & a22*b\n",
        "\\end{pmatrix} \n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9eMuxghNjecQ"
      },
      "source": [
        "In python we can use the tensordot() function to do tensor product: Given two tensors (arrays of dimension greater than or equal to one), a and b, and an array_like object containing two array_like objects, (a_axes, b_axes), sum the products of a's and b's elements (components) over the axes specified by a_axes and b_axes. The third argument can be a single non-negative integer_like scalar, N; if it is such, then the last N dimensions of a and the first N dimensions of b are summed over. To calculate the tensor product, also called the tensor dot product in NumPy, the axis must be set to 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aDp50UBYjecQ",
        "pycharm": {
          "is_executing": false
        },
        "colab": {}
      },
      "source": [
        "# tensor product for vectors\n",
        "A = np.array([[1,2],[1,2]])\n",
        "B = np.array([[3,4],[3,4]])\n",
        "\n",
        "C = np.tensordot(A, B, axes=0)\n",
        "\n",
        "print(C.shape)\n",
        "print(C)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eP-M4hFejecV"
      },
      "source": [
        "## Tensordot\n",
        "To better understand the usage of tensordot in Python, we provide some exercises. The basic [usage](https://docs.scipy.org/doc/numpy/reference/generated/numpy.tensordot.html) is: \n",
        "\n",
        "c=numpy.tensordot(a, b, axes=2),\n",
        "\n",
        "where a, b, are tensors, axes should be int or array_like. If axes is int M, this function will sum over the last M axes of a the first M axes of b in order. If axes is a list of axes to be summed over, then first sequence will apply to a and second to b. Note, the first sequence and second sequence must be of the same length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6X49qtXtjecV",
        "colab": {}
      },
      "source": [
        "## axes is int\n",
        "a = np.random.randint(0,10,(2,2))\n",
        "b = np.random.randint(0,10,(2,2))\n",
        "\n",
        "print(a.shape)\n",
        "print(b.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "foVf-usIlFLl",
        "colab": {}
      },
      "source": [
        "c = np.tensordot(a,b, axes=0) ### tensor product(the definition)\n",
        "print(c)\n",
        "print(c.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Tpamr3UklHNY",
        "colab": {}
      },
      "source": [
        "c = np.tensordot(a,b, axes=1) ### tensor dot product a.b\n",
        "print(c)\n",
        "print(c.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nCuAZbillJ90",
        "colab": {}
      },
      "source": [
        "c = np.tensordot(a,b, axes=2)  ### tensor double contraction a:b\n",
        "print(c)\n",
        "print(c.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0kPAPgeujecX",
        "colab": {}
      },
      "source": [
        "## axes is array_like\n",
        "a = np.random.randint(0,10,(3,4,5)) ## creat a tensor with shape [3,4,5]\n",
        "b = np.random.randint(0,10,(4,5,2)) ## creat a tensor with shape [4,5,2]\n",
        "\n",
        "c = np.tensordot(a,b,[(1,2),(0,1)])\n",
        "\n",
        "### the shape of a is [3,4,5], using the first and the second axis we can create a new matrix with shape [4,5].\n",
        "### For b we use the zero axis and the first axis to create a matrix with shape [4,5]. \n",
        "### Then for these two matrix we do tensor hadamard product and sum all the elements of the result matrix. \n",
        "\n",
        "print(np.sum(a[0]*b[:,:,0]))\n",
        "\n",
        "print(c)\n",
        "print(c.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CarGrQedjece"
      },
      "source": [
        "## Other operation\n",
        "\n",
        "If we already have a tensor with shape (M,N,R), however, we need a new shape (M,W) where W=R* N, or (R,N,M) for the next step, we can use reshape function or transpose to achieve this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X8kAN_8gjece"
      },
      "source": [
        "### [Reshape](https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T1XBQcPvjece",
        "colab": {}
      },
      "source": [
        "a = np.random.randint(0,10,(3,4,5))\n",
        "b = a.reshape((12,5))\n",
        "print(a.shape)\n",
        "print(b.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oOVgCtVZjecg"
      },
      "source": [
        "### [Transpose](https://docs.scipy.org/doc/numpy/reference/generated/numpy.transpose.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o44N-slcjech",
        "colab": {}
      },
      "source": [
        "a = np.random.randint(0,10,(3,4,5)) ## the shape of a is [3,4,5] the index of each axis is [0,1,2]. \n",
        "                                    ## We transpose the tensor according to this index array.\n",
        "b = a.transpose(2,1,0)\n",
        "print(a.shape)\n",
        "print(b.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnFoYYFGSoA1",
        "colab_type": "text"
      },
      "source": [
        "# Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PI3OK95FSoA1",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 1: tensordot\n",
        "\n",
        "Given two tensors as follows:\n",
        "\n",
        "    a = np.random.randint(0,10,(4,4,5))\n",
        "    b = np.random.randint(0,10,(3,4,4))\n",
        "\n",
        "Calculate the tensordot of the two tensors. How can we obtain a result tensor of shape `(5, 3)`?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GoyLgDX3jecY",
        "colab": {}
      },
      "source": [
        "# write your answer here\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zjIB5mnqjeci"
      },
      "source": [
        "## Exercise 2: transpose\n",
        "\n",
        "Given a tensor \n",
        "\n",
        "    a = np.random.randint(0, 10, (3,4,5,6))\n",
        "\n",
        "How can we get a tensor b with shape `(4,5,6,3)` from tensor a?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tG7jOV2ImLi5",
        "colab": {}
      },
      "source": [
        "# write your answer here\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMsVPYMH2Ptx",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 3: random seeds\n",
        "\n",
        "Given a tensor \n",
        "\n",
        "    a = np.random.randint(0, 10, (3,4,5,6))\n",
        "\n",
        "How can we make sure the entries in the tensor `a` same each time when we run the block ? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HpenXRcOGc2z",
        "colab": {}
      },
      "source": [
        "# write your answer here\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wPc3dYB2Su6",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 4: transpose and reshape\n",
        "\n",
        "Given a tensor \n",
        "\n",
        "    a = np.random.randint(0, 10, (3,4,5,6))\n",
        "    b = b.tanspose(3,2,0,1)\n",
        "    b = b.reshape((30,12))\n",
        "\n",
        "How can we get back to tensor `a` from tensor `b`?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyKd4nBY2VuG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# write your answer here\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}